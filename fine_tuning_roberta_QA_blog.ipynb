{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4kqY_vMw4uE"
      },
      "source": [
        "# Question answering (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQFpse9vw4uH"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQy49T3Ow4uI"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9at42Nv2w4uJ"
      },
      "source": [
        "You will need to setup git, adapt your email and name in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYZfcD9zw4uJ"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"96harsh56@gmail.com\"\n",
        "!git config --global user.name \"96harsh56\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsfinIb1w4uK"
      },
      "source": [
        "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih6qLFCyw4uK"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Access token : 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\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0REDR-Pzw4uK"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUoZKPD1w4uP"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"microsoft/deberta-v2-xxlarge\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AG3zGtUw4uQ"
      },
      "outputs": [],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "reY5ettMcqhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq_ECt2_w4uU"
      },
      "outputs": [],
      "source": [
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "\n",
        "def preprocess_training_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = sample_map[i]\n",
        "        answer = answers[sample_idx]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label is (0, 0)\n",
        "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_train=pd.read_csv('/content/drive/MyDrive/SubjQA/train.csv', encoding='latin-1')\n",
        "df_test=pd.read_csv('/content/drive/MyDrive/SubjQA/test.csv', encoding='latin-1')"
      ],
      "metadata": {
        "id": "V5x_vR5hA5AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wApyqYUSxbQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "LAnPb4F6CzoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[0].question"
      ],
      "metadata": {
        "id": "ft8StfAUC8aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[0].review"
      ],
      "metadata": {
        "id": "6f_KQY81ZrcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[0].human_ans_indices"
      ],
      "metadata": {
        "id": "uaY0trFXZ1V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[0].review[1568:1585]"
      ],
      "metadata": {
        "id": "0VTZMVM3aIzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train=df_train[['question','human_ans_indices','review','human_ans_spans']]\n",
        "df_test=df_test[['question','human_ans_indices','review','human_ans_spans']]"
      ],
      "metadata": {
        "id": "Snt7riL9al9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df_train['id']=np.linspace(0,len(df_train)-1,len(df_train))\n",
        "df_test['id']=np.linspace(0,len(df_test)-1,len(df_test))\n",
        "\n",
        "df_train['id']=df_train['id'].astype(str)\n",
        "df_test['id']=df_test['id'].astype(str)"
      ],
      "metadata": {
        "id": "IzlrHX2_gIwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(df_train.iloc[0].human_ans_indices.split('(')[1].split(',')[0])"
      ],
      "metadata": {
        "id": "lzDgyu11bYsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float(df_train.iloc[0].human_ans_indices.split('(')[1].split(',')[1].split(' ')[1].split(')')[0])"
      ],
      "metadata": {
        "id": "NQHlRc42cH_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['answers']=df_train['human_ans_spans']\n",
        "df_test['answers']=df_test['human_ans_spans']"
      ],
      "metadata": {
        "id": "HwT5cbsocuZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(df_train)):\n",
        "  answer1={}\n",
        "  si=int(df_train.iloc[i].human_ans_indices.split('(')[1].split(',')[0])\n",
        "  ei=int(df_train.iloc[i].human_ans_indices.split('(')[1].split(',')[1].split(' ')[1].split(')')[0])\n",
        "  answer1['text']=[df_train.iloc[i].review[si:ei]]\n",
        "  answer1['answer_start']=[si]\n",
        "  df_train.at[i, 'answers']=answer1\n",
        "  #print(df_train.iloc[i].answers,df_train.iloc[i].human_ans_spans)"
      ],
      "metadata": {
        "id": "uMnG_vaBBHCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(df_test)):\n",
        "  answer1={}\n",
        "  si=int(df_test.iloc[i].human_ans_indices.split('(')[1].split(',')[0])\n",
        "  ei=int(df_test.iloc[i].human_ans_indices.split('(')[1].split(',')[1].split(' ')[1].split(')')[0])\n",
        "  answer1['text']=[df_test.iloc[i].review[si:ei]]\n",
        "  answer1['answer_start']=[si]\n",
        "  df_test.at[i, 'answers']=answer1\n",
        "  #print(df_train.iloc[i].answers,df_train.iloc[i].human_ans_spans)"
      ],
      "metadata": {
        "id": "8iR114ydBHIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "Egar_QEr922s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns=['question', 'human_ans_indices', 'context', 'human_ans_spans', 'id',\n",
        "       'answers']\n",
        "\n",
        "df_test.columns=['question', 'human_ans_indices', 'context', 'human_ans_spans','id',\n",
        "       'answers']"
      ],
      "metadata": {
        "id": "qQSnCnyXfP93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset2 = datasets.Dataset.from_pandas(df_test)\n",
        "train_dataset2 = datasets.Dataset.from_pandas(df_train)\n"
      ],
      "metadata": {
        "id": "-lIKzelVe5Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset2.map(\n",
        "    preprocess_training_examples,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset2.column_names,\n",
        ")\n",
        "len(train_dataset2), len(train_dataset)"
      ],
      "metadata": {
        "id": "E1_4_zoKD4rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset2.shape"
      ],
      "metadata": {
        "id": "gS8_nWXhMyJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_validation_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"id\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "    return inputs\n"
      ],
      "metadata": {
        "id": "kgj6QMxtxdhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBrZLvK6w4uV"
      },
      "outputs": [],
      "source": [
        "validation_dataset = val_dataset2.map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=val_dataset2.column_names,\n",
        ")\n",
        "len(validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation_dataset)"
      ],
      "metadata": {
        "id": "8gRdmEqJESy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset"
      ],
      "metadata": {
        "id": "Co7lBwc9NS18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_dataset2)"
      ],
      "metadata": {
        "id": "lUOrABRrNY1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr9cuPMvw4uW"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZrjF0Srw4uW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_6rtretw4uW"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JZTMpXhw4uX"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"squad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_7O_apPw4uY"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, features, examples):\n",
        "    example_to_features = collections.defaultdict(list)\n",
        "    for idx, feature in enumerate(features):\n",
        "        example_to_features[feature[\"example_id\"]].append(idx)\n",
        "\n",
        "    predicted_answers = []\n",
        "    for example in tqdm(examples):\n",
        "        example_id = example[\"id\"]\n",
        "        context = example[\"context\"]\n",
        "        answers = []\n",
        "\n",
        "        # Loop through all features associated with that example\n",
        "        for feature_index in example_to_features[example_id]:\n",
        "            start_logit = start_logits[feature_index]\n",
        "            end_logit = end_logits[feature_index]\n",
        "            offsets = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Skip answers that are not fully in the context\n",
        "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                        continue\n",
        "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
        "                    if (\n",
        "                        end_index < start_index\n",
        "                        or end_index - start_index + 1 > max_answer_length\n",
        "                    ):\n",
        "                        continue\n",
        "\n",
        "                    answer = {\n",
        "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                    answers.append(answer)\n",
        "\n",
        "        # Select the answer with the best score\n",
        "        if len(answers) > 0:\n",
        "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
        "            predicted_answers.append(\n",
        "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
        "            )\n",
        "        else:\n",
        "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
        "\n",
        "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
        "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-cd7g-Xw4uY"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ],
      "metadata": {
        "id": "0qIddyOD1hT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [\n",
        "\n",
        "'deberta.encoder.conv.conv.bias',\n",
        "'deberta.encoder.conv.LayerNorm.weight',\n",
        "'deberta.encoder.conv.LayerNorm.bias',\n",
        "'qa_outputs.weight',\n",
        "'qa_outputs.bias']\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in lst:\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "C25SIKzA2auH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ],
      "metadata": {
        "id": "6buMpX7jE7sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1V3rhbnw4uY"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "model_name\n",
        "\n",
        "batch_size=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaUzt74Bw4uY"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-squad\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "     per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-2Nt6Qcw4uY"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n_best=20\n",
        "max_answer_length = 30"
      ],
      "metadata": {
        "id": "JbeHOU4hGxB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRYBf6Dgw4uY"
      },
      "outputs": [],
      "source": [
        "predictions, _, _ = trainer.predict(validation_dataset)\n",
        "start_logits, end_logits = predictions\n",
        "compute_metrics(start_logits, end_logits, validation_dataset, val_dataset2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.memory_summary()"
      ],
      "metadata": {
        "id": "MJXUHD3aIh4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "0MJMjqtEqxcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j6KZtSiw4uY"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, _, _ = trainer.predict(validation_dataset)\n",
        "start_logits, end_logits = predictions\n",
        "compute_metrics(start_logits, end_logits, validation_dataset, val_dataset2)"
      ],
      "metadata": {
        "id": "fp-TtJUItPsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eo75AvZx0Ufx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference!"
      ],
      "metadata": {
        "id": "VY8z8z_nr07t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "hBj7TxuRr3Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your own checkpoint\n",
        "model_checkpoint2 = \"96harsh56/roberta-finetuned-subjqa-movies_1110AM \"\n",
        "question_answerer = pipeline(\"question-answering\", model=model_checkpoint2)"
      ],
      "metadata": {
        "id": "PyE79j6b8ANM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_train1=pd.read_csv('/content/drive/MyDrive/SubjQA/train.csv', encoding='latin-1')\n",
        "df_test1=pd.read_csv('/content/drive/MyDrive/SubjQA/test.csv', encoding='latin-1')\n",
        "# df_train1=pd.read_csv('/content/train.csv')\n",
        "# df_test1=pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "HpJcvM4W9EKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train1.iloc[13].question"
      ],
      "metadata": {
        "id": "Z_p1UoaN9NHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = df_train1.iloc[13].review\n",
        "question = df_train1.iloc[13].question\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "id": "dNcZ4iLfLC1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your own checkpoint\n",
        "model_checkpoint_o = \"deepset/roberta-base-squad2\"\n",
        "question_answerer_old = pipeline(\"question-answering\", model=model_checkpoint_o)"
      ],
      "metadata": {
        "id": "cZgxGLaYgSYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = df_train1.iloc[13].review\n",
        "question = df_train1.iloc[13].question\n",
        "question_answerer_old(question=question, context=context)"
      ],
      "metadata": {
        "id": "gDKf50ma8lQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[3].question"
      ],
      "metadata": {
        "id": "5bw7K-qE86s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[3].answers"
      ],
      "metadata": {
        "id": "RDA5sKITN0Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[['id','question','context','answers']].head()"
      ],
      "metadata": {
        "id": "sjEFM-G1N2FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train)"
      ],
      "metadata": {
        "id": "VTJP_JyTOnx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}